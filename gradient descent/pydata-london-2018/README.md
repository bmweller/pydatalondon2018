# Follow the gradient
## An introduction to mathematical optimisation

By Gianluca Campanella (<gianluca@campanella.org>)

[![Creative Commons License](https://i.creativecommons.org/l/by/4.0/80x15.png)](http://creativecommons.org/licenses/by/4.0/)

This repository contains the slides and notebooks for my tutorial *Follow the gradient: an introduction to mathematical optimisation* presented at [PyData London 2018](https://pydata.org/london2018/) in London, UK.

## Materials

* [**Slides**](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/slides/pydata_london_2018.pdf)

* **Notebooks** [![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/gcampanella/pydata-london-2018/master)
  1. [Linearly programmed breakfast](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/notebooks/01_LP_Breakfast.ipynb)
  2. [Knapsack](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/notebooks/02_ILP_Knapsack.ipynb)
  1. [Quantile regression](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/notebooks/03_Quantile_Regression.ipynb)
  1. [Elastic net penalisation](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/notebooks/04_Elastic_Net.ipynb)
  1. [Survival analysis](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/notebooks/05_Survival_Analysis.ipynb)
  1. [Multi-layer perceptron](https://cdn.rawgit.com/gcampanella/pydata-london-2018/master/notebooks/06_MLP.ipynb)

## Additional resources

* **Books**
  * [*Convex Optimization*](https://web.stanford.edu/~boyd/cvxbook/)
  * [*Introduction to Nonlinear and Global Optimization*](https://www.springer.com/us/book/9780387886695)
  * [*Numerical Optimization*](https://www.springer.com/us/book/9780387303031)
  * [*Optimization â€“ Theory and Practice*](https://www.springer.com/us/book/9780387789767)

* **Courses**
  * [CVX101](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)
  * [EE364a: Convex Optimization I](https://web.stanford.edu/class/ee364a/)
