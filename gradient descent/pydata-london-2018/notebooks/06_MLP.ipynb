{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam\n",
    "from autograd.scipy.misc import logsumexp\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the *MNIST database of handwritten digits* from [Keras](https://keras.io/datasets/#mnist-database-of-handwritten-digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten images to vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise to unit interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X = X_train.max()\n",
    "X_train = X_train / max_X\n",
    "X_test = X_test / max_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode `y` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to predict classes given weights and biases (as `parameters`) and the data `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    for W, b in parameters:\n",
    "        y_hat = np.dot(X, W) + b\n",
    "        X = np.tanh(y_hat)\n",
    "    return y_hat - logsumexp(y_hat, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function to minimise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(parameters, X, y):\n",
    "    return -np.sum(y * predict(parameters, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to measure the accuracy of predictions made using `parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(parameters, X, y):\n",
    "    y = np.argmax(y, axis=1)\n",
    "    y_hat = np.argmax(predict(parameters, X), axis=1)\n",
    "    return np.mean(y_hat == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to randomly initialise weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init(sigma, sizes, prng=np.random.RandomState(seed=42)):\n",
    "    return [(sigma * prng.randn(m, n), sigma * prng.randn(n))  # (weights, biases)\n",
    "            for m, n in zip(sizes[:-1], sizes[1:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for the neural network and optimisation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = (X_train.shape[1], 200, 100, y_train.shape[1])\n",
    "sigma = 0.1\n",
    "batch_size = 256\n",
    "n_epochs = 5\n",
    "step_size = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute number of batches and define a function to generate batch indices given the iteration number `it`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "def batch_indices(it):\n",
    "    idx = it % n_batches\n",
    "    return slice(idx * batch_size, (idx + 1) * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objective function and its gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(parameters, it):\n",
    "    idx = batch_indices(it)\n",
    "    return loss(parameters, X_train[idx], y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_grad = grad(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise parameters randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = random_init(sigma, layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check initial predictions and loss for the first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.70023786, -2.44684557, -2.14167641, -1.54998636, -1.96201996,\n",
       "        -1.82885366, -2.5333151 , -2.5707044 , -3.64097556, -3.40339709],\n",
       "       [-2.5604389 , -2.84849808, -2.80874001, -1.50753379, -1.87884739,\n",
       "        -2.01618161, -2.70002861, -2.06754373, -3.65626445, -2.55613636],\n",
       "       [-2.54389909, -2.81593475, -2.4844252 , -2.43473089, -1.82139518,\n",
       "        -2.34067401, -2.58995902, -2.2891326 , -2.14069762, -1.97627763],\n",
       "       [-2.15704758, -2.85468154, -2.0956475 , -2.62614572, -2.07549301,\n",
       "        -2.10108898, -3.29443049, -1.94373585, -2.4252526 , -2.16385303],\n",
       "       [-2.70961953, -2.36461903, -2.5948118 , -2.05592123, -2.07706406,\n",
       "        -1.60714808, -2.26015076, -2.76119053, -2.79174911, -2.49863842]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(parameters, X_train[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593.5535733141162"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective(parameters, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimise using [Adam](https://arxiv.org/abs/1412.6980)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration | Training accuracy | Test accuracy\n",
      "        0 |             9.93% |         9.62%\n",
      "        1 |            94.01% |        93.99%\n",
      "        2 |            96.08% |        95.63%\n",
      "        3 |            97.19% |        96.50%\n",
      "        4 |            97.82% |        96.92%\n"
     ]
    }
   ],
   "source": [
    "print('Iteration | Training accuracy | Test accuracy')\n",
    "def print_accuracy(parameters, it, gradient):\n",
    "    if it % n_batches == 0:\n",
    "        train_accuracy = accuracy(parameters, X_train, y_train)\n",
    "        test_accuracy = accuracy(parameters, X_test, y_test)\n",
    "        print('{:9} | {:16.2f}% | {:12.2f}%'.format(it // n_batches,\n",
    "                                                    train_accuracy * 100,\n",
    "                                                    test_accuracy * 100))\n",
    "\n",
    "opt_parameters = adam(\n",
    "    grad=objective_grad,\n",
    "    x0=parameters,\n",
    "    callback=print_accuracy,\n",
    "    num_iters=n_epochs * n_batches,\n",
    "    step_size=step_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
